import os
import tempfile
import torch
import streamlit as st
import whisper
import pysrt
import numpy as np
import warnings
import collections
import contextlib
import wave
import subprocess
import json
from tqdm import tqdm
from datetime import timedelta
import time
import re
from dotenv import load_dotenv
from openai import OpenAI
import anthropic

# API í‚¤ ì €ì¥ íŒŒì¼ ê²½ë¡œ
API_KEYS_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), ".api_keys.json")

def load_saved_api_keys():
    """ì €ì¥ëœ API í‚¤ë¥¼ íŒŒì¼ì—ì„œ ë¡œë“œ"""
    try:
        if os.path.exists(API_KEYS_FILE):
            with open(API_KEYS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        st.warning(f"API í‚¤ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    return {}

def save_api_keys(openai_key=None, anthropic_key=None):
    """API í‚¤ë¥¼ íŒŒì¼ì— ì €ì¥"""
    try:
        keys = load_saved_api_keys()
        if openai_key is not None:
            keys['openai_api_key'] = openai_key
        if anthropic_key is not None:
            keys['anthropic_api_key'] = anthropic_key
        with open(API_KEYS_FILE, 'w', encoding='utf-8') as f:
            json.dump(keys, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        st.error(f"API í‚¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False

def delete_saved_api_keys():
    """ì €ì¥ëœ API í‚¤ íŒŒì¼ ì‚­ì œ"""
    try:
        if os.path.exists(API_KEYS_FILE):
            os.remove(API_KEYS_FILE)
        return True
    except Exception as e:
        st.error(f"API í‚¤ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

warnings.filterwarnings("ignore", message="FP16 is not supported on CPU; using FP32 instead")
warnings.filterwarnings("ignore", category=FutureWarning)

def check_gpu_status():
    """GPU ê°ì§€ ë° ì‚¬ìš© ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” í•¨ìˆ˜"""
    gpu_info = {
        "is_available": torch.cuda.is_available(),
        "device_count": torch.cuda.device_count() if torch.cuda.is_available() else 0,
        "current_device": None,
        "device_name": None,
        "memory_allocated": None,
        "memory_reserved": None,
        "memory_total": None
    }
    
    if gpu_info["is_available"]:
        current_device = torch.cuda.current_device()
        gpu_info["current_device"] = current_device
        gpu_info["device_name"] = torch.cuda.get_device_name(current_device)
        
        # ë‹¨ìœ„ ë³€í™˜ í•¨ìˆ˜ (ë°”ì´íŠ¸ -> GB)
        def bytes_to_gb(bytes_value):
            return round(bytes_value / (1024**3), 2)
        
        try:
            gpu_info["memory_allocated"] = bytes_to_gb(torch.cuda.memory_allocated(current_device))
            gpu_info["memory_reserved"] = bytes_to_gb(torch.cuda.memory_reserved(current_device))
            
            # ì „ì²´ VRAM ìš©ëŸ‰ í™•ì¸ (Windows ì „ìš©)
            if os.name == 'nt':
                try:
                    # nvidia-smi ëª…ë ¹ì–´ ì‹¤í–‰
                    import subprocess
                    result = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.total', '--format=csv,noheader,nounits'], 
                                               universal_newlines=True)
                    memory_total = int(result.strip())
                    gpu_info["memory_total"] = memory_total / 1024  # MB -> GB
                except:
                    gpu_info["memory_total"] = "í™•ì¸ ë¶ˆê°€"
            else:
                gpu_info["memory_total"] = "í™•ì¸ ë¶ˆê°€"
        except:
            # ë©”ëª¨ë¦¬ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ëŠ” ê²½ìš°
            gpu_info["memory_allocated"] = "í™•ì¸ ë¶ˆê°€"
            gpu_info["memory_reserved"] = "í™•ì¸ ë¶ˆê°€"
            gpu_info["memory_total"] = "í™•ì¸ ë¶ˆê°€"
    
    return gpu_info

def display_gpu_info():
    """GPU ì •ë³´ë¥¼ Streamlit UIì— í‘œì‹œí•˜ëŠ” í•¨ìˆ˜"""
    gpu_info = check_gpu_status()
    
    # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥¸ ìƒ‰ìƒ ë° ë©”ì‹œì§€ í‘œì‹œ
    if gpu_info["is_available"]:
        st.success("ğŸ® GPU ê°ì§€ë¨!")
        
        # GPU ì •ë³´ í‘œì‹œ
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("ê°ì§€ëœ GPU ìˆ˜", gpu_info["device_count"])
            st.write(f"**ëª¨ë¸**: {gpu_info['device_name']}")
        
        with col2:
            if isinstance(gpu_info["memory_allocated"], (int, float)):
                st.metric("ì‚¬ìš© ì¤‘ì¸ VRAM", f"{gpu_info['memory_allocated']} GB")
            else:
                st.write("**ì‚¬ìš© ì¤‘ì¸ VRAM**: í™•ì¸ ë¶ˆê°€")
                
            if isinstance(gpu_info["memory_total"], (int, float)):
                st.metric("ì „ì²´ VRAM", f"{round(gpu_info['memory_total'], 1)} GB")
            else:
                st.write("**ì „ì²´ VRAM**: í™•ì¸ ë¶ˆê°€")
        
        # Whisper ëª¨ë¸ì˜ GPU ì‚¬ìš© ì„¤ì •
        st.info(f"ğŸ” Whisper ëª¨ë¸ í™•ì¸: GPU ì‚¬ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤! {gpu_info['device_name']}ì—ì„œ ì‚¬ìš©ë¥ ì´ ë‚®ì€ ê²½ìš° GPU ë¶€í•˜ê°€ ë‚®ê±°ë‚˜ CPUë¡œ ì¼ë¶€ ì‘ì—…ì´ ì²˜ë¦¬ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # í™˜ê²½ ë³€ìˆ˜ í™•ì¸ - expander ì‚¬ìš©í•˜ì§€ ì•Šê³  ì§ì ‘ í‘œì‹œ
        st.subheader("ğŸ› ï¸ GPU ìµœì í™” ì„¤ì • í™•ì¸")
        cuda_env_vars = {
            "CUDA_VISIBLE_DEVICES": os.environ.get("CUDA_VISIBLE_DEVICES", "ì„¤ì •ë˜ì§€ ì•ŠìŒ"),
            "PYTORCH_CUDA_ALLOC_CONF": os.environ.get("PYTORCH_CUDA_ALLOC_CONF", "ì„¤ì •ë˜ì§€ ì•ŠìŒ"),
            "TF_FORCE_GPU_ALLOW_GROWTH": os.environ.get("TF_FORCE_GPU_ALLOW_GROWTH", "ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        }
        
        for var_name, var_value in cuda_env_vars.items():
            st.write(f"**{var_name}**: {var_value}")
        
        if all(value == "ì„¤ì •ë˜ì§€ ì•ŠìŒ" for value in cuda_env_vars.values()):
            st.warning("GPU ê´€ë ¨ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•„ìš”í•œ ê²½ìš° ìµœì í™”ë¥¼ ìœ„í•´ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        
        # Torch ë²„ì „ ì •ë³´
        st.write(f"**PyTorch ë²„ì „**: {torch.__version__}")
        st.write(f"**CUDA ë²„ì „**: {torch.version.cuda or 'ì‚¬ìš© ë¶ˆê°€'}")
    else:
        st.warning("âš ï¸ GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        st.write("Whisper ëª¨ë¸ì€ CPUì—ì„œë„ ì‘ë™í•˜ì§€ë§Œ, ì²˜ë¦¬ ì†ë„ê°€ ëŠë¦½ë‹ˆë‹¤.")
        
        # ê°€ëŠ¥í•œ ì›ì¸ ë° í•´ê²°ì±… - expander ì—†ì´ ì§ì ‘ í‘œì‹œ
        st.subheader("ê°€ëŠ¥í•œ ì›ì¸ ë° í•´ê²°ì±…")
        st.write("""
        - **CUDAê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ**: PyTorch CUDA ë²„ì „ì„ ì„¤ì¹˜í•˜ì„¸ìš”: `pip install torch --index-url https://download.pytorch.org/whl/cu121`
        - **ë“œë¼ì´ë²„ ë¬¸ì œ**: ìµœì‹  NVIDIA ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
        - **CUDA ë²„ì „ ë¶ˆì¼ì¹˜**: PyTorchì™€ í˜¸í™˜ë˜ëŠ” CUDA ë²„ì „ì„ ì„¤ì¹˜í•˜ì„¸ìš”.
        - **í™˜ê²½ ë³€ìˆ˜ ë¬¸ì œ**: 'CUDA_VISIBLE_DEVICES' í™˜ê²½ ë³€ìˆ˜ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
        """)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'vad_module_loaded' not in st.session_state:
    st.session_state.vad_module_loaded = False

# VAD ëª¨ë“ˆ ë¡œë“œ ì‹œë„
try:
    import webrtcvad
    st.session_state.vad_module_loaded = True
except ImportError:
    st.warning("webrtcvad ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install webrtcvad'ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”. VAD ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")

class Frame(object):
    """VADë¥¼ ìœ„í•œ í”„ë ˆì„ í´ë˜ìŠ¤"""
    def __init__(self, bytes, timestamp, duration):
        self.bytes = bytes
        self.timestamp = timestamp
        self.duration = duration

def frame_generator(frame_duration_ms, audio, sample_rate):
    """ì˜¤ë””ì˜¤ë¥¼ í”„ë ˆì„ìœ¼ë¡œ ë¶„í• """
    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)
    offset = 0
    timestamp = 0.0
    duration = (float(n) / sample_rate) / 2.0
    while offset + n < len(audio):
        yield Frame(audio[offset:offset + n], timestamp, duration)
        timestamp += duration
        offset += n

def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames):
    """VADë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± êµ¬ê°„ ê°ì§€"""
    num_padding_frames = int(padding_duration_ms / frame_duration_ms)
    ring_buffer = collections.deque(maxlen=num_padding_frames)
    triggered = False
    voiced_frames = []
    
    for frame in frames:
        is_speech = vad.is_speech(frame.bytes, sample_rate)
        
        if not triggered:
            ring_buffer.append((frame, is_speech))
            num_voiced = len([f for f, speech in ring_buffer if speech])
            
            if num_voiced > 0.9 * ring_buffer.maxlen:
                triggered = True
                for f, s in ring_buffer:
                    voiced_frames.append(f)
                ring_buffer.clear()
        else:
            voiced_frames.append(frame)
            ring_buffer.append((frame, is_speech))
            num_unvoiced = len([f for f, speech in ring_buffer if not speech])
            
            if num_unvoiced > 0.9 * ring_buffer.maxlen:
                triggered = False
                yield (voiced_frames[0].timestamp,
                      voiced_frames[-1].timestamp + voiced_frames[-1].duration,
                      b''.join([f.bytes for f in voiced_frames]))
                ring_buffer.clear()
                voiced_frames = []
    
    if voiced_frames:
        yield (voiced_frames[0].timestamp,
               voiced_frames[-1].timestamp + voiced_frames[-1].duration,
               b''.join([f.bytes for f in voiced_frames]))

def process_with_vad(audio_path, aggressiveness=1):
    """VADë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± êµ¬ê°„ ì²˜ë¦¬"""
    if not st.session_state.vad_module_loaded:
        # VADë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ì „ì²´ ì˜¤ë””ì˜¤ë¥¼ í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ì²˜ë¦¬
        import soundfile as sf
        info = sf.info(audio_path)
        return [(0, info.duration)]
    
    with contextlib.closing(wave.open(audio_path, 'rb')) as wf:
        pcm_data = wf.readframes(wf.getnframes())
        sample_rate = wf.getframerate()
        sample_width = wf.getsampwidth()
    
    vad = webrtcvad.Vad(aggressiveness)
    frames = frame_generator(30, pcm_data, sample_rate)
    frames = list(frames)
    segments = vad_collector(sample_rate, 30, 2000, vad, frames)
    
    voice_segments = []
    for start, end, _ in segments:
        voice_segments.append((start, end))
    
    return voice_segments

class PromptManager:
    def __init__(self, prompts_dir="prompts"):
        self.prompts_dir = prompts_dir
        self.system_prompt = self._load_prompt("system_prompt.md")
        self.user_prompt_template = self._load_prompt("user_prompt.md")
    
    def _load_prompt(self, filename):
        """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ"""
        try:
            prompt_path = os.path.join(self.prompts_dir, filename)
            with open(prompt_path, 'r', encoding='utf-8') as f:
                return f.read().strip()
        except Exception as e:
            st.error(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({filename}): {str(e)}")
            return ""
    
    def get_user_prompt(self, context, current_sub, previous_subs, next_subs):
        """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return self.user_prompt_template.format(
            context=context or 'ì—†ìŒ',
            previous_subs='\n'.join(previous_subs) if previous_subs else 'ì—†ìŒ',
            current_sub=current_sub,
            next_subs='\n'.join(next_subs) if next_subs else 'ì—†ìŒ'
        )

class SubtitleGenerator:
    def __init__(self, model_size="small", llm_provider=None):
        with st.spinner("Whisper ëª¨ë¸ ë¡œë”© ì¤‘..."):
            self.model = whisper.load_model(model_size)
        st.success("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

        self.llm_provider = llm_provider
        self.prompt_manager = PromptManager()
        
        self.llm_client = None
        if llm_provider == "openai":
            openai_api_key = os.getenv("OPENAI_API_KEY") or st.session_state.get('openai_api_key')
            if openai_api_key:
                self.llm_client = OpenAI(api_key=openai_api_key)
            else:
                st.warning("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì •ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif llm_provider == "anthropic":
            anthropic_api_key = os.getenv("ANTHROPIC_API_KEY") or st.session_state.get('anthropic_api_key')
            if anthropic_api_key:
                self.llm_client = anthropic.Anthropic(api_key=anthropic_api_key)
            else:
                st.warning("Anthropic API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì •ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    def convert_to_wav(self, input_file):
        """ì—…ë¡œë“œëœ íŒŒì¼ì„ WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        try:
            # ì„ì‹œ íŒŒì¼ ìƒì„±
            with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_wav:
                temp_wav_path = temp_wav.name
            
            # ì›ë³¸ íŒŒì¼ì„ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(input_file.name)[1]) as temp_input:
                temp_input.write(input_file.getbuffer())
                temp_input_path = temp_input.name
            
            # FFmpegë¥¼ ì‚¬ìš©í•œ ë³€í™˜
            try:
                import ffmpeg
                
                # FFmpegë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€í™˜
                (
                    ffmpeg
                    .input(temp_input_path)
                    .output(temp_wav_path, acodec='pcm_s16le', ar=16000, ac=1)
                    .run(quiet=True, overwrite_output=True)
                )
                
                # íŒŒì¼ ê¸¸ì´ í™•ì¸
                probe = ffmpeg.probe(temp_wav_path)
                audio_info = next(s for s in probe['streams'] if s['codec_type'] == 'audio')
                total_seconds = float(audio_info.get('duration', 0))
                
                return temp_wav_path, total_seconds, temp_input_path
                
            except ImportError:
                st.error("ffmpeg-python íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install ffmpeg-python'ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
                raise
            except ffmpeg.Error as e:
                st.error(f"FFmpeg ë³€í™˜ ì˜¤ë¥˜: {e.stderr.decode() if e.stderr else str(e)}")
                raise
                
        except Exception as e:
            st.error(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            st.error(traceback.format_exc())
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if 'temp_input_path' in locals() and os.path.exists(temp_input_path):
                os.unlink(temp_input_path)
            if 'temp_wav_path' in locals() and os.path.exists(temp_wav_path):
                os.unlink(temp_wav_path)
                
            return None, None, None

    def merge_short_subtitles(self, subtitles, min_chars):
        """ì§§ì€ ìë§‰ë“¤ì„ ë³‘í•©"""
        if not subtitles:
            return subtitles
        
        merged = []
        current = subtitles[0]
        
        for next_sub in subtitles[1:]:
            # í˜„ì¬ ìë§‰ì´ ìµœì†Œ ê¸€ì ìˆ˜ë³´ë‹¤ ì ê³ , ë‹¤ìŒ ìë§‰ê³¼ì˜ ì‹œê°„ ê°„ê²©ì´ 2ì´ˆ ì´ë‚´ì¸ ê²½ìš°
            if (len(current.text) < min_chars and 
                (next_sub.start.hours * 3600 + next_sub.start.minutes * 60 + next_sub.start.seconds) - 
                (current.end.hours * 3600 + current.end.minutes * 60 + current.end.seconds) <= 2):
                
                # ë³‘í•©ëœ í…ìŠ¤íŠ¸ê°€ ìµœëŒ€ ê¸€ì ìˆ˜ë¥¼ ì´ˆê³¼í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ë§Œ ë³‘í•©
                if len(current.text + " " + next_sub.text) <= 100:  # ê¸°ë³¸ ìµœëŒ€ ê¸€ì ìˆ˜ ì œí•œ
                    current.text += " " + next_sub.text
                    current.end = next_sub.end
                else:
                    merged.append(current)
                    current = next_sub
            else:
                merged.append(current)
                current = next_sub
        
        merged.append(current)
        
        # ì¸ë±ìŠ¤ ì¬ì •ë ¬
        for i, sub in enumerate(merged, 1):
            sub.index = i
        
        return merged

    def correct_subtitle_with_llm(self, subtitle_text, context=None, previous_subs=None, next_subs=None):
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ìë§‰ í…ìŠ¤íŠ¸ë¥¼ êµì •"""
        if not self.llm_client:
            return subtitle_text
        
        try:
            # ì›ë³¸ ìë§‰ ë¡œê·¸ ì¶”ê°€
            log_entry = f"ì›ë³¸ ìë§‰: {subtitle_text}"
            if 'correction_logs' not in st.session_state:
                st.session_state.correction_logs = []
            st.session_state.correction_logs.append(log_entry)
            
            if self.llm_provider == "openai":
                response = self.llm_client.chat.completions.create(
                    model="gpt-5-mini",
                    messages=[
                        {"role": "system", "content": self.prompt_manager.system_prompt},
                        {"role": "user", "content": self.prompt_manager.get_user_prompt(
                            context, subtitle_text, previous_subs, next_subs
                        )}
                    ],
                )
                corrected_text = response.choices[0].message.content.strip()
                
            elif self.llm_provider == "anthropic":
                response = self.llm_client.messages.create(
                    model="claude-haiku-4-5",
                    max_tokens=1000,
                    system=self.prompt_manager.system_prompt,
                    messages=[{
                        "role": "user", 
                        "content": self.prompt_manager.get_user_prompt(
                            context, subtitle_text, previous_subs, next_subs
                        )
                    }]
                )
                corrected_text = response.content[0].text.strip()
            
            # êµì •ëœ ìë§‰ ë¡œê·¸ ì¶”ê°€
            log_entry = f"êµì •ëœ ìë§‰: {corrected_text}"
            st.session_state.correction_logs.append(log_entry)
            
            # ìë™ ìŠ¤í¬ë¡¤ì„ ìœ„í•´ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.log_updated = True
            
            return corrected_text
                
        except Exception as e:
            error_msg = f"ìë§‰ êµì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            st.session_state.correction_logs.append(error_msg)
            return subtitle_text
        
    def _update_correction_log_display(self, log_placeholder):
        """êµì • ë¡œê·¸ ë””ìŠ¤í”Œë ˆì´ ì—…ë°ì´íŠ¸"""
        if 'correction_logs' not in st.session_state or not st.session_state.correction_logs:
            return
        
        # HTML í˜•ì‹ìœ¼ë¡œ ë¡œê·¸ êµ¬ì„±
        log_html = "<div class='log-container' id='log-container'>"
        reversed_logs = list(reversed(st.session_state.correction_logs))
        
        for i, log in enumerate(reversed_logs):
            if "ì›ë³¸ ìë§‰:" in log:
                log_html += f"<div class='original-subtitle'>{log}</div>"
            elif "êµì •ëœ ìë§‰:" in log:
                if i < len(st.session_state.correction_logs) - 1:
                    log_html += "<div class='log-divider'></div>"
                log_html += f"<div class='corrected-subtitle'>{log}</div>"
            elif "ì˜¤ë¥˜" in log:
                log_html += f"<div class='error-message'>{log}</div>"
        
        log_html += "</div>"
        
        # ë¡œê·¸ í‘œì‹œ
        log_placeholder.markdown(log_html, unsafe_allow_html=True)

    def generate_subtitles(self, audio_file, progress_bar, status_text, language=None, max_chars=None, min_chars=None, max_duration=None, context=None, vad_enabled=True, vad_aggressiveness=1):
        """ìë§‰ ìƒì„± í•¨ìˆ˜"""
        temp_files = []

        # ë¡œê·¸ ì»¨í…Œì´ë„ˆ ì´ˆê¸°í™”
        st.session_state.correction_logs = []
        process_container = st.container()
        status_container = process_container.container()
        log_container = process_container.container()
        # êµì • ë¡œê·¸ ìŠ¤íƒ€ì¼ ì •ì˜
        log_container.markdown("""
        <style>
        .log-container {
            height: 250px;
            overflow-y: auto;
            background-color: #f0f2f6;
            padding: 10px;
            border-radius: 5px;
            margin-bottom: 10px;
            font-family: monospace;
            border: 1px solid #ddd;
        }
        .original-subtitle {
            color: #555;
            margin-bottom: 4px;
        }
        .corrected-subtitle {
            color: #0066cc;
            margin-bottom: 12px;
            font-weight: bold;
        }
        .error-message {
            color: #cc0000;
            font-weight: bold;
        }
        .log-divider {
            border-bottom: 1px dashed #ccc;
            margin: 8px 0;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # ë¡œê·¸ í‘œì‹œ ì˜ì—­
        log_heading = log_container.empty()
        log_placeholder = log_container.empty()
        
        # ë¡œê·¸ ì œëª© ì„¤ì •
        if self.llm_client:
            log_heading.subheader("ì‹¤ì‹œê°„ ìë§‰ êµì • ë¡œê·¸")
        
        try:
            # WAV íŒŒì¼ ìƒì„±
            wav_path, total_seconds, temp_input_path = self.convert_to_wav(audio_file)
            if not wav_path:
                return None
            
            temp_files.extend([wav_path, temp_input_path])
            status_text.text("WAV íŒŒì¼ ìƒì„± ì™„ë£Œ")
            progress_bar.progress(10)
            
            # VADë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± êµ¬ê°„ ê°ì§€
            if vad_enabled:
                status_text.text("ìŒì„± êµ¬ê°„ ê°ì§€ ì¤‘...")
                voice_segments = process_with_vad(wav_path, vad_aggressiveness)
                status_text.text(f"ê°ì§€ëœ ìŒì„± êµ¬ê°„: {len(voice_segments)}ê°œ")
            else:
                # VADë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš° ì „ì²´ ì˜¤ë””ì˜¤ë¥¼ í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ì²˜ë¦¬
                import soundfile as sf
                info = sf.info(wav_path)
                voice_segments = [(0, info.duration)]
                status_text.text("VAD ë¹„í™œì„±í™”: ì „ì²´ ì˜¤ë””ì˜¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•©ë‹ˆë‹¤")
                
            progress_bar.progress(20)
            
            # ì „ì²´ ìë§‰ ì •ë³´ ì €ì¥ìš©
            all_segments = []
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
            import soundfile as sf
            audio, sample_rate = sf.read(wav_path)
            audio = audio.astype(np.float32)
            
            # ìŒì„± êµ¬ê°„ ì²˜ë¦¬
            status_text.text("ìŒì„± ì¸ì‹ ì‹œì‘...")
            total_segments = len(voice_segments)
            
            for i, (start, end) in enumerate(voice_segments):
                status_text.text(f"ìŒì„± êµ¬ê°„ {i+1}/{total_segments} ì²˜ë¦¬ ì¤‘...")
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                segment_progress = 20 + (i / total_segments * 40)
                progress_bar.progress(int(segment_progress))
                
                # í˜„ì¬ êµ¬ê°„ì˜ ì˜¤ë””ì˜¤ ì¶”ì¶œ
                start_sample = int(start * sample_rate)
                end_sample = min(int(end * sample_rate), len(audio))
                segment_audio = audio[start_sample:end_sample]
                
                # Whisperë¡œ ìŒì„± ì¸ì‹
                transcribe_options = {}
                if language:
                    transcribe_options["language"] = language
                    
                result = self.model.transcribe(segment_audio, **transcribe_options)
                
                # ì„¸ê·¸ë¨¼íŠ¸ ì‹œê°„ ì¡°ì • ë° ì •ë³´ ì €ì¥
                for segment in result["segments"]:
                    adj_segment = {
                        "start": start + segment["start"],
                        "end": start + segment["end"],
                        "text": segment["text"].strip(),
                        "processed": False  # ì´ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í‘œì‹œ
                    }
                    all_segments.append(adj_segment)

            status_text.text("ìŒì„± ì¸ì‹ ì™„ë£Œ!")
            progress_bar.progress(60)

            # LLM êµì • ì²˜ë¦¬
            if self.llm_client:
                status_text.text("LLM ìë§‰ êµì • ì‹œì‘...")
                
                # ì „ì²´ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜
                total_segments = len(all_segments)
                
                for i, segment in enumerate(all_segments):
                    # ì´ì „/ë‹¤ìŒ ìë§‰ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (ìµœëŒ€ 2ê°œì”©)
                    previous_texts = [all_segments[j]["text"] for j in range(max(0, i-2), i)]
                    next_texts = [all_segments[j]["text"] for j in range(i+1, min(len(all_segments), i+3))]
                    
                    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                    segment_progress = 60 + ((i / total_segments) * 30)
                    progress_bar.progress(int(segment_progress))
                    
                    # LLMìœ¼ë¡œ ìë§‰ êµì •
                    status_text.text(f"ìë§‰ êµì • ì¤‘... ({i+1}/{total_segments})")
                    
                    segment["text"] = self.correct_subtitle_with_llm(
                        segment["text"], context, previous_texts, next_texts
                    )
                    
                    # ë¡œê·¸ ì—…ë°ì´íŠ¸ ë° í™”ë©´ ê°±ì‹ 
                    self._update_correction_log_display(log_placeholder)

            # ìë§‰ íŒŒì¼ ìƒì„±
            status_text.text("ìë§‰ íŒŒì¼ ìƒì„± ì¤‘...")
            subs = pysrt.SubRipFile()
            subtitle_index = 1

            # í…ìŠ¤íŠ¸ ë¶„í•  ë° ìë§‰ ìƒì„±
            for segment in all_segments:
                if not segment["text"]:  # ë¹ˆ í…ìŠ¤íŠ¸ëŠ” ê±´ë„ˆë›°ê¸°
                    continue
                
                text = segment["text"]
                start_time = segment["start"]
                end_time = segment["end"]
                duration = end_time - start_time
                
                # ìµœëŒ€ ì‹œê°„ ê¸¸ì´ ì²´í¬
                if max_duration and duration > max_duration:
                    # ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ë¶„í• 
                    num_splits = int(np.ceil(duration / max_duration))
                    sub_duration = duration / num_splits
                    
                    # í…ìŠ¤íŠ¸ë¥¼ ê¸€ì ìˆ˜ì— ë¹„ë¡€í•˜ì—¬ ê³µì •í•˜ê²Œ ë¶„í• 
                    splits = []
                    
                    # í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í•  (ë” ìì—°ìŠ¤ëŸ¬ìš´ ë¶„í•  ì§€ì )
                    sentence_breaks = re.split(r'([.!?] )', text)
                    sentences = []
                    
                    # ë¬¸ì¥ ì¬êµ¬ì„± (êµ¬ë¶„ì í¬í•¨)
                    i = 0
                    while i < len(sentence_breaks):
                        if i + 1 < len(sentence_breaks) and re.match(r'[.!?] ', sentence_breaks[i+1]):
                            sentences.append(sentence_breaks[i] + sentence_breaks[i+1])
                            i += 2
                        else:
                            sentences.append(sentence_breaks[i])
                            i += 1
                    
                    # ë¹ˆ ë¬¸ì¥ ì œê±°
                    sentences = [s for s in sentences if s.strip()]
                    
                    if not sentences:  # ë¬¸ì¥ì´ ì—†ìœ¼ë©´ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„í• 
                        words = text.split()
                        chars_per_split = len(text) / num_splits
                        current_split = []
                        current_length = 0
                        
                        for word in words:
                            if current_length + len(word) + (1 if current_length > 0 else 0) <= chars_per_split:
                                current_split.append(word)
                                current_length += len(word) + (1 if current_length > 0 else 0)
                            else:
                                if current_split:  # í˜„ì¬ ë¶„í• ì„ ì¶”ê°€
                                    splits.append(' '.join(current_split))
                                current_split = [word]
                                current_length = len(word)
                        
                        if current_split:  # ë§ˆì§€ë§‰ ë¶„í•  ì¶”ê°€
                            splits.append(' '.join(current_split))
                    else:
                        # ë¬¸ì¥ì„ ì ì ˆíˆ ê·¸ë£¹í™”í•˜ì—¬ ë¶„í• 
                        current_split = []
                        current_length = 0
                        target_length = len(text) / num_splits
                        
                        for sentence in sentences:
                            if current_length + len(sentence) <= target_length * 1.3:  # 30% ì—¬ìœ  í—ˆìš©
                                current_split.append(sentence)
                                current_length += len(sentence)
                            else:
                                if current_split:
                                    splits.append(''.join(current_split).strip())
                                current_split = [sentence]
                                current_length = len(sentence)
                        
                        if current_split:
                            splits.append(''.join(current_split).strip())
                    
                    # í•„ìš”í•œ ê²½ìš° ë¶„í•  ìˆ˜ ë§ì¶”ê¸°
                    while len(splits) < num_splits:
                        # ê°€ì¥ ê¸´ ë¶„í• ì„ ì°¾ì•„ ë¶„í• 
                        longest_idx = max(range(len(splits)), key=lambda i: len(splits[i]))
                        longest_split = splits[longest_idx]
                        
                        if len(longest_split) < 10:  # ë„ˆë¬´ ì§§ìœ¼ë©´ ë¶„í• í•˜ì§€ ì•ŠìŒ
                            break
                            
                        mid_point = len(longest_split) // 2
                        # ê³µë°±ì„ ì°¾ì•„ ë¶„í• ì  ì¡°ì •
                        while mid_point > 0 and mid_point < len(longest_split) - 1:
                            if longest_split[mid_point] == ' ':
                                break
                            mid_point += 1
                            
                        if mid_point == 0 or mid_point >= len(longest_split) - 1:
                            # ì ì ˆí•œ ë¶„í• ì ì„ ì°¾ì§€ ëª»í•˜ë©´ ê·¸ëƒ¥ ì¤‘ê°„ì—ì„œ ìë¦„
                            mid_point = len(longest_split) // 2
                        
                        first_half = longest_split[:mid_point].strip()
                        second_half = longest_split[mid_point:].strip()
                        
                        splits[longest_idx] = first_half
                        splits.insert(longest_idx + 1, second_half)
                    
                    # ì‹œê°„ ë¶„ë°°
                    current_time = start_time
                    for split_text in splits:
                        split_ratio = len(split_text) / sum(len(s) for s in splits)
                        split_duration = duration * split_ratio
                        split_end = current_time + split_duration
                        
                        if max_chars and len(split_text) > max_chars:
                            # ê¸€ì ìˆ˜ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ì¶”ê°€ ë¶„í•  (ë‹¨ì–´ ê²½ê³„ ìœ ì§€)
                            words = split_text.split()
                            current_chunk = ""
                            chunks = []
                            
                            for word in words:
                                test_chunk = (current_chunk + " " + word).strip()
                                if len(test_chunk) <= max_chars:
                                    current_chunk = test_chunk
                                else:
                                    if current_chunk:
                                        chunks.append(current_chunk)
                                    current_chunk = word
                            
                            if current_chunk:
                                chunks.append(current_chunk)
                            
                            # ë¶„í• ëœ ì²­í¬ì— ì‹œê°„ ë°°ë¶„
                            chunk_time = current_time
                            chunk_duration = split_duration / len(chunks)
                            for chunk in chunks:
                                chunk_end = chunk_time + chunk_duration
                                
                                # ìë§‰ ì•„ì´í…œ ìƒì„± ë° ì¶”ê°€
                                hours = int(chunk_time) // 3600
                                minutes = (int(chunk_time) % 3600) // 60
                                seconds = int(chunk_time) % 60
                                milliseconds = int((chunk_time % 1) * 1000)
                                start_time_item = pysrt.SubRipTime(hours=hours, minutes=minutes, 
                                                        seconds=seconds, milliseconds=milliseconds)
                                
                                hours = int(chunk_end) // 3600
                                minutes = (int(chunk_end) % 3600) // 60
                                seconds = int(chunk_end) % 60
                                milliseconds = int((chunk_end % 1) * 1000)
                                end_time_item = pysrt.SubRipTime(hours=hours, minutes=minutes, 
                                                    seconds=seconds, milliseconds=milliseconds)
                                
                                sub = pysrt.SubRipItem(
                                    index=subtitle_index,
                                    start=start_time_item,
                                    end=end_time_item,
                                    text=chunk
                                )
                                subs.append(sub)
                                subtitle_index += 1
                                
                                chunk_time = chunk_end
                        else:
                            # ìµœëŒ€ ê¸€ì ìˆ˜ ì´ë‚´ì¸ ê²½ìš° ë‹¨ì¼ ìë§‰ìœ¼ë¡œ ì¶”ê°€
                            hours = int(current_time) // 3600
                            minutes = (int(current_time) % 3600) // 60
                            seconds = int(current_time) % 60
                            milliseconds = int((current_time % 1) * 1000)
                            start_time_item = pysrt.SubRipTime(hours=hours, minutes=minutes, 
                                                    seconds=seconds, milliseconds=milliseconds)
                            
                            hours = int(split_end) // 3600
                            minutes = (int(split_end) % 3600) // 60
                            seconds = int(split_end) % 60
                            milliseconds = int((split_end % 1) * 1000)
                            end_time_item = pysrt.SubRipTime(hours=hours, minutes=minutes, 
                                                seconds=seconds, milliseconds=milliseconds)
                            
                            sub = pysrt.SubRipItem(
                                index=subtitle_index,
                                start=start_time_item,
                                end=end_time_item,
                                text=split_text
                            )
                            subs.append(sub)
                            subtitle_index += 1
                        
                        current_time = split_end
                else:
                    # ìµœëŒ€ ì‹œê°„ ì´ë‚´ì¸ ê²½ìš° ìµœëŒ€ ê¸€ì ìˆ˜ì— ë”°ë¼ ì²˜ë¦¬
                    if max_chars and len(text) > max_chars:
                        # ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„í• 
                        words = text.split()
                        current_text = ""
                        sub_splits = []
                        
                        for word in words:
                            test_text = (current_text + " " + word).strip()
                            if len(test_text) <= max_chars:
                                current_text = test_text
                            else:
                                if current_text:
                                    sub_splits.append(current_text)
                                current_text = word
                        
                        if current_text:  # ë§ˆì§€ë§‰ ë¶€ë¶„ ì¶”ê°€
                            sub_splits.append(current_text)
                        
                        # ì‹œê°„ì„ í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë¹„ë¡€í•˜ì—¬ ë¶„ë°°
                        sub_duration = end_time - start_time
                        total_chars = sum(len(s) for s in sub_splits)
                        current_time = start_time
                        
                        for sub_text in sub_splits:
                            ratio = len(sub_text) / total_chars
                            split_duration = sub_duration * ratio
                            split_end = current_time + split_duration
                            
                            hours = int(current_time) // 3600
                            minutes = (int(current_time) % 3600) // 60
                            seconds = int(current_time) % 60
                            milliseconds = int((current_time % 1) * 1000)
                            start_time_item = pysrt.SubRipTime(hours=hours, minutes=minutes, 
                                                    seconds=seconds, milliseconds=milliseconds)
                            
                            hours = int(split_end) // 3600
                            minutes = (int(split_end) % 3600) // 60
                            seconds = int(split_end) % 60
                            milliseconds = int((split_end % 1) * 1000)
                            end_time_item = pysrt.SubRipTime(hours=hours, minutes=minutes, 
                                                seconds=seconds, milliseconds=milliseconds)
                            
                            sub = pysrt.SubRipItem(
                                index=subtitle_index,
                                start=start_time_item,
                                end=end_time_item,
                                text=sub_text
                            )
                            subs.append(sub)
                            subtitle_index += 1
                            
                            current_time = split_end
                    else:
                        # ê·¸ëŒ€ë¡œ ì¶”ê°€
                        hours = int(start_time) // 3600
                        minutes = (int(start_time) % 3600) // 60
                        seconds = int(start_time) % 60
                        milliseconds = int((start_time % 1) * 1000)
                        start_time_item = pysrt.SubRipTime(hours=hours, minutes=minutes, 
                                                seconds=seconds, milliseconds=milliseconds)
                        
                        hours = int(end_time) // 3600
                        minutes = (int(end_time) % 3600) // 60
                        seconds = int(end_time) % 60
                        milliseconds = int((end_time % 1) * 1000)
                        end_time_item = pysrt.SubRipTime(hours=hours, minutes=minutes, 
                                            seconds=seconds, milliseconds=milliseconds)
                        
                        sub = pysrt.SubRipItem(
                            index=subtitle_index,
                            start=start_time_item,
                            end=end_time_item,
                            text=text
                        )
                        subs.append(sub)
                        subtitle_index += 1
            
            # ìµœì†Œ ê¸€ì ìˆ˜ ì œí•œì´ ì„¤ì •ëœ ê²½ìš° ì§§ì€ ìë§‰ ë³‘í•©
            if min_chars:
                status_text.text("ì§§ì€ ìë§‰ ë³‘í•© ì¤‘...")
                merged_subs = self.merge_short_subtitles(subs, min_chars)
                subs = pysrt.SubRipFile()
                for sub in merged_subs:
                    subs.append(sub)
            
            # ì„ì‹œ SRT íŒŒì¼ ìƒì„±
            with tempfile.NamedTemporaryFile(delete=False, suffix='.srt') as temp_srt:
                temp_srt_path = temp_srt.name
                temp_files.append(temp_srt_path)
            
            subs.save(temp_srt_path, encoding='utf-8')
            status_text.text("ìë§‰ íŒŒì¼ ìƒì„± ì™„ë£Œ!")
            progress_bar.progress(100)
            
            # SRT íŒŒì¼ ë‚´ìš© ì½ê¸°
            with open(temp_srt_path, 'r', encoding='utf-8') as f:
                srt_content = f.read()
            
            return srt_content
            
        except Exception as e:
            st.error(f"ìë§‰ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            st.error(traceback.format_exc())
            return None
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for temp_file in temp_files:
                if os.path.exists(temp_file):
                    os.unlink(temp_file)

    def convert_srt_to_vtt(self, srt_content):
        """SRT í˜•ì‹ì˜ ìë§‰ì„ VTT í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        # VTT í—¤ë” ì¶”ê°€
        vtt_content = "WEBVTT\n\n"
        
        # SRT ë¸”ë¡ ë‹¨ìœ„ë¡œ ë¶„í• 
        srt_blocks = srt_content.strip().split('\n\n')
        
        for block in srt_blocks:
            lines = block.split('\n')
            
            # ê° ë¸”ë¡ì€ ìµœì†Œ 3ì¤„ ì´ìƒì´ì–´ì•¼ í•¨ (ì¸ë±ìŠ¤, ì‹œê°„, í…ìŠ¤íŠ¸)
            if len(lines) >= 3:
                # ì¸ë±ìŠ¤ ë¼ì¸ì€ ê±´ë„ˆë›°ê¸°
                
                # ì‹œê°„ í¬ë§· ë³€í™˜ (00:00:00,000 --> 00:00:00.000)
                time_line = lines[1].replace(',', '.')
                
                # í…ìŠ¤íŠ¸ ë¼ì¸ ìœ ì§€
                text_lines = lines[2:]
                
                # VTT ë¸”ë¡ ìƒì„±
                vtt_block = time_line + '\n' + '\n'.join(text_lines)
                vtt_content += vtt_block + '\n\n'
        
        return vtt_content

def save_to_subtitle_history(filename, srt_content, vtt_content=None, correction_logs=None):
    """ìë§‰ê³¼ êµì • ë¡œê·¸ë¥¼ íˆìŠ¤í† ë¦¬ì— ì €ì¥í•˜ê³  ìƒì„±ëœ IDë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    if not filename or not srt_content:
        return None
    
    # ê³ ìœ  ì‹ë³„ì ìƒì„± (íŒŒì¼ëª… + íƒ€ì„ìŠ¤íƒ¬í”„)
    current_time = time.time()
    unique_id = f"{filename}_{current_time}"
    
    # ì¤‘ë³µ í™•ì¸
    exists = False
    existing_id = None
    for item in st.session_state.subtitle_history:
        if item['filename'] == filename and item['content'] == srt_content:
            exists = True
            existing_id = item.get('id')
            break
    
    # ì¤‘ë³µì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì €ì¥
    if not exists:
        # ìë§‰ íˆìŠ¤í† ë¦¬ì— ì €ì¥
        st.session_state.subtitle_history.append({
            'id': unique_id,
            'filename': filename,
            'content': srt_content,
            'vtt_content': vtt_content,
            'timestamp': current_time
        })
        
        # êµì • ë¡œê·¸ê°€ ìˆìœ¼ë©´ ë¡œê·¸ íˆìŠ¤í† ë¦¬ì— ì €ì¥
        if correction_logs:
            st.session_state.correction_logs_history[unique_id] = correction_logs.copy()
        
        # ëª©ë¡ì´ ë„ˆë¬´ ê¸¸ì–´ì§€ëŠ” ê²ƒì„ ë°©ì§€ (ìµœëŒ€ 10ê°œ ì €ì¥)
        if len(st.session_state.subtitle_history) > 10:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            oldest_item = st.session_state.subtitle_history.pop(0)
            # ê´€ë ¨ ë¡œê·¸ë„ ì œê±°
            if oldest_item.get('id') in st.session_state.correction_logs_history:
                del st.session_state.correction_logs_history[oldest_item['id']]
        
        return unique_id
    else:
        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ê¸°ì¡´ ID ë°˜í™˜
        return existing_id

def main():
    st.set_page_config(
        page_title="ìë™ ìë§‰ ìƒì„±ê¸°",
        page_icon="ğŸ¬",
        layout="wide"
    )

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'vad_module_loaded' not in st.session_state:
        st.session_state.vad_module_loaded = False

    # ì €ì¥ëœ API í‚¤ ë¡œë“œ
    if 'api_keys_loaded' not in st.session_state:
        saved_keys = load_saved_api_keys()
        st.session_state.openai_api_key = saved_keys.get('openai_api_key', '')
        st.session_state.anthropic_api_key = saved_keys.get('anthropic_api_key', '')
        st.session_state.save_api_keys_enabled = bool(saved_keys)  # ì €ì¥ëœ í‚¤ê°€ ìˆìœ¼ë©´ ì²´í¬ë°•ìŠ¤ í™œì„±í™”
        st.session_state.api_keys_loaded = True

    if 'openai_api_key' not in st.session_state:
        st.session_state.openai_api_key = ""
    if 'anthropic_api_key' not in st.session_state:
        st.session_state.anthropic_api_key = ""
    if 'save_api_keys_enabled' not in st.session_state:
        st.session_state.save_api_keys_enabled = False
    if 'last_srt_content' not in st.session_state:
        st.session_state.last_srt_content = None
    if 'last_filename' not in st.session_state:
        st.session_state.last_filename = None
    if 'show_last_preview' not in st.session_state:
        st.session_state.show_last_preview = False
    if 'correction_logs' not in st.session_state:
        st.session_state.correction_logs = []
    if 'subtitle_history' not in st.session_state:
        st.session_state.subtitle_history = []
    if 'correction_logs_history' not in st.session_state:
        st.session_state.correction_logs_history = {}

    # êµì • ë¡œê·¸ í‘œì‹œ ì˜ì—­ ìƒì„±
    if 'show_logs' not in st.session_state:
        st.session_state.show_logs = False
    
    # VAD ëª¨ë“ˆ ë¡œë“œ ì‹œë„
    try:
        import webrtcvad
        st.session_state.vad_module_loaded = True
    except ImportError:
        st.warning("webrtcvad ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install webrtcvad'ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”. VAD ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
    
    # ì‚¬ì´ë“œë°” - ì„¤ì •
    with st.sidebar:
        st.title("âš™ï¸ ì„¤ì •")

        with st.expander("GPU ì •ë³´", expanded=False):
            display_gpu_info()

        if torch.cuda.is_available():
            with st.expander("GPU ìµœì í™” ì˜µì…˜", expanded=False):
                st.info("ìµœì‹  GPUëŠ” Whisper ëª¨ë¸ì—ëŠ” ë†’ì€ ì‚¬ìš©ë¥ ì´ í•„ìš”í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                use_half_precision = st.checkbox("Half Precision ì‚¬ìš© (FP16, ë©”ëª¨ë¦¬ ì ˆì•½)", value=True)
                device_id = st.selectbox(
                    "GPU ì¥ì¹˜ ì„ íƒ", 
                    options=list(range(torch.cuda.device_count())),
                    format_func=lambda x: f"GPU {x}: {torch.cuda.get_device_name(x)}",
                    index=0
                )
                
                if use_half_precision:
                    os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:128"
        
        # API í‚¤ ì„¤ì •
        with st.expander("API í‚¤ ì„¤ì •", expanded=False):
            openai_key = st.text_input(
                "OpenAI API í‚¤",
                type="password",
                value=st.session_state.openai_api_key,
                key="openai_api_key_input"
            )
            anthropic_key = st.text_input(
                "Anthropic API í‚¤",
                type="password",
                value=st.session_state.anthropic_api_key,
                key="anthropic_api_key_input"
            )

            # API í‚¤ ì €ì¥ ì²´í¬ë°•ìŠ¤
            save_keys = st.checkbox(
                "API í‚¤ ì €ì¥ (ë‹¤ìŒ ì‹¤í–‰ ì‹œì—ë„ ìœ ì§€)",
                value=st.session_state.save_api_keys_enabled,
                help="ì²´í¬í•˜ë©´ API í‚¤ê°€ ë¡œì»¬ íŒŒì¼ì— ì €ì¥ë©ë‹ˆë‹¤. ì €ì¥ëœ í‚¤ëŠ” .gitignoreì— ì˜í•´ GitHubì— ì—…ë¡œë“œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            )

            if openai_key:
                os.environ["OPENAI_API_KEY"] = openai_key
                st.session_state.openai_api_key = openai_key

            if anthropic_key:
                os.environ["ANTHROPIC_API_KEY"] = anthropic_key
                st.session_state.anthropic_api_key = anthropic_key

            # ì €ì¥ ìƒíƒœ ë³€ê²½ ì²˜ë¦¬
            if save_keys != st.session_state.save_api_keys_enabled:
                st.session_state.save_api_keys_enabled = save_keys
                if save_keys:
                    # ì²´í¬ë°•ìŠ¤ í™œì„±í™”: API í‚¤ ì €ì¥
                    if save_api_keys(openai_key, anthropic_key):
                        st.success("API í‚¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    # ì²´í¬ë°•ìŠ¤ ë¹„í™œì„±í™”: ì €ì¥ëœ API í‚¤ ì‚­ì œ
                    if delete_saved_api_keys():
                        st.info("ì €ì¥ëœ API í‚¤ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
            elif save_keys and (openai_key or anthropic_key):
                # ì²´í¬ë°•ìŠ¤ê°€ í™œì„±í™”ëœ ìƒíƒœì—ì„œ í‚¤ê°€ ë³€ê²½ë˜ë©´ ìë™ ì €ì¥
                save_api_keys(openai_key if openai_key else None, anthropic_key if anthropic_key else None)
        
        # ëª¨ë¸ ì„¤ì •
        whisper_model = st.selectbox(
            "Whisper ëª¨ë¸ í¬ê¸°",
            options=["tiny", "base", "small", "medium", "large"],
            index=2
        )
        
        llm_provider = st.radio(
            "LLM êµì • ì œê³µì",
            options=["ì‚¬ìš©ì•ˆí•¨", "OpenAI", "Anthropic"],
            index=0
        )
        
        if llm_provider == "OpenAI":
            llm_provider = "openai"
        elif llm_provider == "Anthropic":
            llm_provider = "anthropic"
        else:
            llm_provider = None
        
        # VAD ì„¤ì •
        vad_enabled = st.checkbox("VAD(Voice Activity Detection) ì‚¬ìš©", value=True, 
                               help="ìŒì„±ì´ ìˆëŠ” ë¶€ë¶„ë§Œ ê°ì§€í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤. ë¹„í™œì„±í™”í•˜ë©´ ì „ì²´ ì˜¤ë””ì˜¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        if vad_enabled and st.session_state.vad_module_loaded:
            vad_aggressiveness = st.slider("VAD ê°ë„", min_value=0, max_value=3, value=1, 
                                        help="ë†’ì„ìˆ˜ë¡ ë” ì—„ê²©í•˜ê²Œ ìŒì„±ì„ ê°ì§€í•©ë‹ˆë‹¤. 0: ë§¤ìš° ê´€ëŒ€, 3: ë§¤ìš° ì—„ê²©")
        else:
            vad_aggressiveness = 1
        
        # ìë§‰ ì„¤ì •
        language = st.selectbox(
            "ìë§‰ ì–¸ì–´",
            options=["ìë™ ê°ì§€", "í•œêµ­ì–´", "ì˜ì–´", "ì¼ë³¸ì–´", "ì¤‘êµ­ì–´"],
            index=0
        )
        
        lang_code = None
        if language == "í•œêµ­ì–´":
            lang_code = "ko"
        elif language == "ì˜ì–´":
            lang_code = "en"
        elif language == "ì¼ë³¸ì–´":
            lang_code = "ja"
        elif language == "ì¤‘êµ­ì–´":
            lang_code = "zh"
        
        max_chars = st.number_input("í•œ ìë§‰ë‹¹ ìµœëŒ€ ê¸€ì ìˆ˜", min_value=0, value=40)
        if max_chars <= 0:
            max_chars = None
            
        min_chars = st.number_input("í•œ ìë§‰ë‹¹ ìµœì†Œ ê¸€ì ìˆ˜", min_value=0, value=6)
        if min_chars <= 0:
            min_chars = None
            
        max_duration = st.number_input("í•œ ìë§‰ë‹¹ ìµœëŒ€ ì‹œê°„(ì´ˆ)", min_value=0.0, value=10.0)
        if max_duration <= 0:
            max_duration = None
        
        context = st.text_area("ì˜ìƒ ì»¨í…ìŠ¤íŠ¸ (ì˜ìƒì˜ ì£¼ì œ, ëª©ì , ëŒ€ìƒ ì²­ì¤‘ ë“±)", height=100)
        if not context:
            context = None
    
    # ë©”ì¸ ì»¨í…ì¸ 
    st.title("ğŸ¬ ìë™ ìë§‰ ìƒì„±ê¸°")
    st.write("ìŒì„± ë˜ëŠ” ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ìë™ìœ¼ë¡œ ìë§‰ì„ ìƒì„±í•˜ì„¸ìš”.")
    
    # ê³ ê¸‰ ì˜µì…˜
    with st.expander("ì˜µì…˜ ì„¤ëª…", expanded=False):
        st.info("VAD(Voice Activity Detection)ëŠ” ì˜¤ë””ì˜¤ì—ì„œ ìŒì„±ì´ ìˆëŠ” ë¶€ë¶„ë§Œ ê°ì§€í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì¤‘ê°„ ì¤‘ê°„ ì˜¤ë””ì˜¤ ê³µë°±ì´ ìˆëŠ” ì˜ìƒ ë° ìŒì„± íŒŒì¼ì—ì„œ íš¨ê³¼ì ì…ë‹ˆë‹¤.")
        st.warning("webrtcvad ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° VAD ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    
    # ìë§‰ íˆìŠ¤í† ë¦¬ í‘œì‹œ
    if 'subtitle_history' in st.session_state and len(st.session_state.subtitle_history) > 0:
        with st.expander("ì´ì „ ìë§‰ íˆìŠ¤í† ë¦¬", expanded=False):
            for i, item in enumerate(reversed(st.session_state.subtitle_history)):
                col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
                
                with col1:
                    st.write(f"{item['filename']} ({time.strftime('%Y-%m-%d %H:%M', time.localtime(item['timestamp']))})")
                
                with col2:
                    st.download_button(
                        label="SRT",
                        data=item['content'],
                        file_name=f"{item['filename'].split('.')[0]}.srt",
                        mime="text/plain",
                        key=f"srt_download_{i}",
                        use_container_width=True
                    )
                
                with col3:
                    if item.get('vtt_content'):
                        st.download_button(
                            label="VTT",
                            data=item['vtt_content'],
                            file_name=f"{item['filename'].split('.')[0]}.vtt",
                            mime="text/plain",
                            key=f"vtt_download_{i}",
                            use_container_width=True
                        )
                    else:
                        st.write("VTT ì—†ìŒ")
                
                with col4:
                    if st.button("ë¡œë“œ", key=f"load_history_{i}", use_container_width=True):
                        # í˜„ì¬ í‘œì‹œ ì¤‘ì¸ ìë§‰ì´ ìˆìœ¼ë©´ íˆìŠ¤í† ë¦¬ì— ì €ì¥ (íˆìŠ¤í† ë¦¬ ë¡œë“œ ì „ì—)
                        if st.session_state.last_srt_content is not None and st.session_state.last_filename is not None:
                            save_to_subtitle_history(
                                st.session_state.last_filename,
                                st.session_state.last_srt_content,
                                st.session_state.get('last_vtt_content'),
                                st.session_state.get('correction_logs', [])
                            )
                        
                        # íˆìŠ¤í† ë¦¬ì—ì„œ ì„ íƒí•œ ìë§‰ ë¡œë“œ
                        st.session_state.last_srt_content = item['content']
                        st.session_state.last_filename = item['filename']
                        if item.get('vtt_content'):
                            st.session_state.last_vtt_content = item['vtt_content']

                        # ìë§‰ ID ì €ì¥
                        st.session_state.current_subtitle_id = item.get('id')
                        
                        # ê´€ë ¨ êµì • ë¡œê·¸ê°€ ìˆìœ¼ë©´ ë¡œë“œ
                        if item.get('id') in st.session_state.correction_logs_history:
                            st.session_state.correction_logs = st.session_state.correction_logs_history[item['id']].copy()
                        else:
                            # ë¡œê·¸ê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
                            st.session_state.correction_logs = []
                        
                        st.rerun()
                
                st.markdown("---")
    
    # ì´ì „ì— ìƒì„±ëœ ìë§‰ì´ ìˆìœ¼ë©´ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ê³¼ ë¯¸ë¦¬ë³´ê¸° ë²„íŠ¼ í‘œì‹œ
    if 'last_srt_content' in st.session_state and st.session_state.last_srt_content:
        with st.container():
            col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
            
            # íŒŒì¼ëª… í™•ì¸
            if 'last_filename' in st.session_state and st.session_state.last_filename:
                video_title = st.session_state.last_filename
                file_name_base = video_title.split('.')[0]
            else:
                video_title = "Unknown"
                file_name_base = "subtitle"
                
            # ì˜ìƒ ì œëª© í‘œì‹œ
            with col1:
                st.info(f"ì´ì „ì— ìƒì„±ëœ ìë§‰: {video_title}")
            
            # SRT ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            with col2:
                st.download_button(
                    label="SRT ë‹¤ìš´ë¡œë“œ",
                    data=st.session_state.last_srt_content,
                    file_name=f"{file_name_base}.srt",
                    mime="text/plain",
                    use_container_width=True
                )
            
            # VTT ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            with col3:
                # SRTë¥¼ VTTë¡œ ë³€í™˜
                if 'last_vtt_content' not in st.session_state or not st.session_state.last_vtt_content:
                    # SubtitleGenerator ê°ì²´ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©, ì—†ìœ¼ë©´ ì„ì‹œë¡œ ìƒì„±
                    if 'subtitle_generator' in st.session_state and st.session_state.subtitle_generator:
                        generator = st.session_state.subtitle_generator
                    else:
                        generator = SubtitleGenerator(model_size="small")
                    
                    st.session_state.last_vtt_content = generator.convert_srt_to_vtt(st.session_state.last_srt_content)
                
                st.download_button(
                    label="VTT ë‹¤ìš´ë¡œë“œ",
                    data=st.session_state.last_vtt_content,
                    file_name=f"{file_name_base}.vtt",
                    mime="text/plain",
                    use_container_width=True
                )
            
            # ë¯¸ë¦¬ë³´ê¸° ë²„íŠ¼
            with col4:
                show_preview = st.button("ë¯¸ë¦¬ë³´ê¸°", key="show_preview_button", use_container_width=True)
            
            # ë¯¸ë¦¬ë³´ê¸° ë²„íŠ¼ì´ í´ë¦­ë˜ë©´ ìë§‰ ë‚´ìš©ê³¼ í…Œì´ë¸” í‘œì‹œ
            if show_preview:
                st.session_state.show_last_preview = True

                # ì €ì¥ëœ í˜„ì¬ ìë§‰ IDê°€ ìˆìœ¼ë©´ ì‚¬ìš©
                if 'current_subtitle_id' in st.session_state and st.session_state.current_subtitle_id:
                    current_id = st.session_state.current_subtitle_id
                    if current_id in st.session_state.correction_logs_history:
                        st.session_state.correction_logs = st.session_state.correction_logs_history[current_id].copy()
                else:
                    # í˜„ì¬ ìë§‰ì˜ ID ì°¾ê¸°
                    current_id = None
                    for item in st.session_state.subtitle_history:
                        if (item['filename'] == st.session_state.last_filename and 
                            item['content'] == st.session_state.last_srt_content):
                            current_id = item.get('id')
                            # IDë¥¼ ì°¾ì•˜ìœ¼ë©´ í•´ë‹¹ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸°
                            if current_id in st.session_state.correction_logs_history:
                                st.session_state.correction_logs = st.session_state.correction_logs_history[current_id].copy()
                                # ì°¾ì€ ID ì €ì¥
                                st.session_state.current_subtitle_id = current_id
                            break
            
            # ìë§‰ ë¯¸ë¦¬ë³´ê¸° ë° êµì • ë¡œê·¸ë¥¼ í•˜ë‚˜ì˜ í™”ë©´ì— í‘œì‹œ
            if st.session_state.get('show_last_preview', False):
                # ë¯¸ë¦¬ë³´ê¸° ë‹«ê¸° ë²„íŠ¼
                if st.button("ë¯¸ë¦¬ë³´ê¸° ë‹«ê¸°", key="hide_preview_button1"):
                    st.session_state.show_last_preview = False
                    st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨

                # êµì • ë¡œê·¸ê°€ ìˆëŠ” ê²½ìš° í‘œì‹œ
                if st.session_state.get('correction_logs') and len(st.session_state.correction_logs) > 0:
                    st.subheader("ìë§‰ êµì • ë¡œê·¸")
                    
                    # êµì • ë¡œê·¸ í‘œì‹œ ìŠ¤íƒ€ì¼
                    st.markdown("""
                    <style>
                    .log-container {
                        height: 400px;
                        overflow-y: auto;
                        background-color: #f0f2f6;
                        padding: 10px;
                        border-radius: 5px;
                        margin-bottom: 10px;
                        font-family: monospace;
                        border: 1px solid #ddd;
                    }
                    .original-subtitle {
                        color: #555;
                        margin-bottom: 4px;
                    }
                    .corrected-subtitle {
                        color: #0066cc;
                        margin-bottom: 12px;
                        font-weight: bold;
                    }
                    .error-message {
                        color: #cc0000;
                        font-weight: bold;
                    }
                    .log-divider {
                        border-bottom: 1px dashed #ccc;
                        margin: 8px 0;
                    }
                    </style>
                    """, unsafe_allow_html=True)
                    
                    # ë¡œê·¸ í‘œì‹œ
                    log_html = "<div class='log-container' id='log-container'>"
                    for i, log in enumerate(st.session_state.correction_logs):
                        if "ì›ë³¸ ìë§‰:" in log:
                            log_html += f"<div class='original-subtitle'>{log}</div>"
                        elif "êµì •ëœ ìë§‰:" in log:
                            log_html += f"<div class='corrected-subtitle'>{log}</div>"
                            if i < len(st.session_state.correction_logs) - 1:
                                log_html += "<div class='log-divider'></div>"
                        elif "ì˜¤ë¥˜" in log:
                            log_html += f"<div class='error-message'>{log}</div>"
                    log_html += "</div>"
                    
                    st.markdown(log_html, unsafe_allow_html=True)
                else:
                    st.info("ì´ ìë§‰ì— ëŒ€í•œ êµì • ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

                with st.expander("ìë§‰ ë‚´ìš©", expanded=True):
                    st.text_area("SRT ìë§‰", st.session_state.last_srt_content, height=200)
                
                # ìë§‰ ë¯¸ë¦¬ë³´ê¸° í…Œì´ë¸”
                st.subheader("ìë§‰ ë¯¸ë¦¬ë³´ê¸°")
                srt_lines = st.session_state.last_srt_content.strip().split('\n\n')
                preview_data = []
                
                for block in srt_lines:
                    lines = block.split('\n')
                    if len(lines) >= 3:
                        try:
                            index = int(lines[0])
                            time_info = lines[1]
                            text = ' '.join(lines[2:])
                            preview_data.append({"ë²ˆí˜¸": index, "ì‹œê°„": time_info, "ìë§‰": text})
                        except:
                            pass
                
                if preview_data:
                    st.dataframe(preview_data, use_container_width=True)
                
                # ë¯¸ë¦¬ë³´ê¸° ë‹«ê¸° ë²„íŠ¼
                if st.button("ë¯¸ë¦¬ë³´ê¸° ë‹«ê¸°", key="hide_preview_button2"):
                    st.session_state.show_last_preview = False
                    st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨

    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ìŒì„± ë˜ëŠ” ì˜ìƒ íŒŒì¼ ì—…ë¡œë“œ", type=["mp3", "wav", "mp4", "avi", "mov", "mkv"])
    
    if uploaded_file is not None:
        st.audio(uploaded_file, format="audio/wav")
        
        if st.button("ìë§‰ ìƒì„± ì‹œì‘", type="primary"):
            # ë¡œê·¸ ì´ˆê¸°í™”
            st.session_state.correction_logs = []

            # í”„ë¡œê·¸ë ˆìŠ¤ ë°”ì™€ ìƒíƒœ í…ìŠ¤íŠ¸
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("Whisper ëª¨ë¸ ë¡œë”© ì¤‘...")
            
            # ìë§‰ ìƒì„±ê¸° ì´ˆê¸°í™”
            generator = SubtitleGenerator(
                model_size=whisper_model,
                llm_provider=llm_provider
            )
            
            progress_bar.progress(10)
            status_text.text("ìë§‰ ìƒì„± ì¤‘...")
            
            # ìë§‰ ìƒì„±
            srt_content = generator.generate_subtitles(
                audio_file=uploaded_file,
                progress_bar=progress_bar,
                status_text=status_text,
                language=lang_code,
                max_chars=max_chars,
                min_chars=min_chars,
                max_duration=max_duration,
                context=context,
                vad_enabled=vad_enabled,
                vad_aggressiveness=vad_aggressiveness
            )

            if srt_content:
                # ì´ì „ ìë§‰ì„ íˆìŠ¤í† ë¦¬ì— ì €ì¥ (ê¸°ì¡´ ìë§‰ì´ ìˆëŠ” ê²½ìš°)
                if st.session_state.last_srt_content is not None and st.session_state.last_filename is not None:
                    save_to_subtitle_history(
                        st.session_state.last_filename,
                        st.session_state.last_srt_content,
                        st.session_state.get('last_vtt_content'),
                        st.session_state.get('correction_logs', [])
                    )

                # ì„¸ì…˜ ìƒíƒœì— ìë§‰ ë‚´ìš© ì €ì¥
                st.session_state.last_srt_content = srt_content
                st.session_state.last_filename = uploaded_file.name
                st.session_state.last_vtt_content = generator.convert_srt_to_vtt(srt_content)

                # ìƒˆ ìë§‰ì„ íˆìŠ¤í† ë¦¬ì— ì €ì¥í•˜ê³  ID ë°”ë¡œ ë°›ê¸°
                if st.session_state.get('correction_logs'):
                    new_subtitle_id = save_to_subtitle_history(
                        uploaded_file.name,
                        srt_content,
                        st.session_state.last_vtt_content,
                        st.session_state.correction_logs
                    )
                    
                    # IDë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•˜ì—¬ ë¯¸ë¦¬ë³´ê¸° ì‹œ ì‚¬ìš©
                    if new_subtitle_id:
                        st.session_state.current_subtitle_id = new_subtitle_id

                # ìë§‰ê³¼ êµì • ë¡œê·¸ë¥¼ ì—°ê²°í•˜ì—¬ ì €ì¥
                if len(st.session_state.get('correction_logs', [])) > 0:
                    # ë°©ê¸ˆ ìƒì„±í•œ ìë§‰ ì°¾ê¸°
                    for item in reversed(st.session_state.subtitle_history):
                        if (item['filename'] == uploaded_file.name and 
                            item['content'] == srt_content):
                            # êµì • ë¡œê·¸ ì €ì¥
                            st.session_state.correction_logs_history[item['id']] = st.session_state.correction_logs.copy()
                            break
                
                # ìë§‰ ìƒì„±ê¸° ì €ì¥ (ë‚˜ì¤‘ì— VTT ë³€í™˜ ë“±ì— ì‚¬ìš©)
                if 'subtitle_generator' not in st.session_state:
                    st.session_state.subtitle_generator = generator

                # ìë§‰ í‘œì‹œ
                st.subheader("ìƒì„±ëœ ìë§‰")
                st.text_area("SRT ìë§‰", srt_content, height=300)
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ë“¤
                file_name_base = uploaded_file.name.split('.')[0]
                
                col1, col2, col3 = st.columns([2, 1, 1])
                
                with col1:
                    st.write("")  # ë¹ˆ ê³µê°„
                
                with col2:
                    st.download_button(
                        label="SRT íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                        data=srt_content,
                        file_name=f"{file_name_base}.srt",
                        mime="text/plain",
                        use_container_width=True
                    )
                
                with col3:
                    st.download_button(
                        label="VTT íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                        data=st.session_state.last_vtt_content,
                        file_name=f"{file_name_base}.vtt",
                        mime="text/plain",
                        use_container_width=True
                    )
                
                # ë¯¸ë¦¬ë³´ê¸° íƒ­ ì¶”ê°€
                st.subheader("ìë§‰ ë¯¸ë¦¬ë³´ê¸°")
                
                # SRT íŒŒì‹±
                srt_lines = srt_content.strip().split('\n\n')
                preview_data = []
                
                for block in srt_lines:
                    lines = block.split('\n')
                    if len(lines) >= 3:
                        try:
                            index = int(lines[0])
                            time_info = lines[1]
                            text = ' '.join(lines[2:])
                            preview_data.append({"ë²ˆí˜¸": index, "ì‹œê°„": time_info, "ìë§‰": text})
                        except:
                            pass
                
                if preview_data:
                    st.dataframe(preview_data, use_container_width=True)

    # í‘¸í„° êµ¬ë¶„ì„ 
    st.markdown("---")

    # í‘¸í„° ì»¨í…Œì´ë„ˆ ìƒì„±
    footer = st.container()

    with footer:
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.markdown(
                """
                <div style="text-align: center; padding: 10px;">
                    <p style="font-size: 0.9em; color: #666;">
                        ì´ í”„ë¡œê·¸ë¨ì€ <a href="https://metamind.kr" target="_blank" style="color: #4B9CFF; text-decoration: none;">ë©”íƒ€ë§ˆì¸ë“œ</a>ê°€ ì œì‘í•˜ì˜€ìœ¼ë©°, ììœ ë¡œìš´ ìˆ˜ì • ë° ê³µìœ ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
                    </p>
                    <p style="font-size: 0.8em; color: #888;">Â© 2025 ë©”íƒ€ë§ˆì¸ë“œ</p>
                </div>
                """, 
                unsafe_allow_html=True
            )

if __name__ == "__main__":
    main()